#!/usr/bin/env python3
"""
Avery AI News Generator - Direct RSS to AI Pipeline
ç‚ºAvery 08:30äº¤ä»˜ç”Ÿæˆå…©å€‹outputï¼šNotionå®Œæ•´ç‰ˆæ—¥å ± + LINEç¤¾ç¾¤å¿«è¨Š
"""

import feedparser
import json
import requests
import re
from datetime import datetime
from typing import List, Dict, Any
from openai import OpenAI
import os
from dotenv import load_dotenv
import subprocess

class AveryNewsGenerator:
    def __init__(self):
        # è¼‰å…¥.envæ–‡ä»¶
        load_dotenv()
        
        self.feeds = {
            'hackernews': 'https://feeds.feedburner.com/TheHackersNews',
            'techcrunch': 'https://techcrunch.com/feed/'
        }
        
        # å˜—è©¦å¤šç¨®æ–¹å¼ç²å–API key
        self.openai_api_key = (
            os.getenv('OPENAI_API_KEY') or 
            os.getenv('OPENAPI') or
            os.getenv('OPENAI_KEY')
        )
        
        if not self.openai_api_key:
            raise ValueError("âŒ æ‰¾ä¸åˆ° OpenAI API keyï¼Œè«‹æª¢æŸ¥ .env æ–‡ä»¶")
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        print(f"ğŸ”‘ Using OpenAI API key: {self.openai_api_key[:10]}...")
        
    def fetch_rss_feeds(self) -> List[Dict[str, Any]]:
        """æŠ“å–RSSä¸¦åˆæ­¥ç¯©é¸"""
        all_articles = []
        
        for source, url in self.feeds.items():
            try:
                feed = feedparser.parse(url)
                print(f"ğŸ“¡ æŠ“å– {source}: {len(feed.entries)} ç¯‡æ–‡ç« ")
                
                for entry in feed.entries[:15]:  # é™åˆ¶æ•¸é‡
                    article = {
                        'title': entry.title,
                        'link': entry.link,
                        'content': self._clean_content(entry.get('summary', '')),
                        'source': source,
                        'published': entry.get('published', ''),
                        'relevance_score': 0
                    }
                    all_articles.append(article)
                    
            except Exception as e:
                print(f"âŒ æŠ“å– {source} å¤±æ•—: {e}")
                
        return all_articles
    
    def _clean_content(self, content: str) -> str:
        """æ¸…ç†HTMLæ¨™ç±¤å’Œå¤šé¤˜ç©ºç™½"""
        # ç§»é™¤HTMLæ¨™ç±¤
        clean = re.sub(r'<[^>]+>', '', content)
        # ç§»é™¤å¤šé¤˜ç©ºç™½
        clean = re.sub(r'\s+', ' ', clean)
        return clean.strip()[:500]  # é™åˆ¶é•·åº¦
    
    def filter_and_score(self, articles: List[Dict]) -> List[Dict]:
        """æ™ºèƒ½ç¯©é¸å’Œè©•åˆ†ï¼ˆè¤‡è£½n8nçš„Code3é‚è¼¯ï¼‰"""
        
        FILTERS = {
            'sources': {
                'hackernews': {
                    'priority_keywords': [
                        'AI', 'ChatGPT', 'Claude', 'Gemini', 'OpenAI', 'Anthropic',
                        'tool', 'app', 'browser', 'editor', 'Python', 'npm'
                    ],
                    'exclude': [
                        'CVE-2025', 'CVE-2024', 'CVSS', 'KEV catalog',
                        'patch', 'vulnerability', 'zero-day',
                        'ransomware', 'backdoor', 'rootkit'
                    ],
                    'max_items': 8
                },
                'techcrunch': {
                    'priority_keywords': [
                        'AI', 'ChatGPT', 'OpenAI', 'Anthropic', 'Gemini',
                        'app', 'tool', 'feature', 'update', 'launch'
                    ],
                    'exclude': [
                        'raises', 'funding', 'valuation', 'Series', 
                        'IPO', 'acquisition', 'Tesla', 'Rivian'
                    ],
                    'max_items': 6
                }
            },
            'bonus_keywords': [
                'tutorial', 'guide', 'how to', 'tips',
                'free', 'open source', 'beginner',
                'automation', 'no-code', 'workflow'
            ]
        }
        
        for article in articles:
            score = 0
            source = article['source']
            config = FILTERS['sources'][source]
            full_text = f"{article['title']} {article['content']}".lower()
            
            # æª¢æŸ¥æ’é™¤é—œéµå­—
            for keyword in config['exclude']:
                if keyword.lower() in full_text:
                    score -= 5
                    
            # æª¢æŸ¥å„ªå…ˆé—œéµå­—
            for keyword in config['priority_keywords']:
                if keyword.lower() in article['title'].lower():
                    score += 10
                elif keyword.lower() in article['content'].lower():
                    score += 5
                    
            # åŠ åˆ†é …ç›®
            for keyword in FILTERS['bonus_keywords']:
                if keyword.lower() in full_text:
                    score += 3
                    
            article['relevance_score'] = score
        
        # æŒ‰ä¾†æºåˆ†çµ„ä¸¦æ’åº
        hackernews_articles = [a for a in articles if a['source'] == 'hackernews']
        techcrunch_articles = [a for a in articles if a['source'] == 'techcrunch']
        
        top_hackernews = sorted(hackernews_articles, key=lambda x: x['relevance_score'], reverse=True)[:8]
        top_techcrunch = sorted(techcrunch_articles, key=lambda x: x['relevance_score'], reverse=True)[:6]
        
        filtered = [a for a in top_hackernews + top_techcrunch if a['relevance_score'] > 0]
        print(f"ğŸ¯ ç¯©é¸å¾Œä¿ç•™: {len(filtered)} ç¯‡æ–‡ç« ")
        
        return sorted(filtered, key=lambda x: x['relevance_score'], reverse=True)
    
    def data_alchemist_processing(self, articles: List[Dict]) -> Dict:
        """æ•¸æ“šç…‰é‡‘è¡“å¸«ï¼šåˆ†é¡å’Œç¿»è­¯"""
        
        articles_text = "\n\n".join([
            f"æ¨™é¡Œ: {article['title']}\né€£çµ: {article['link']}\nå…§å®¹: {article['content']}"
            for article in articles
        ])
        
        prompt = f"""# [ç³»çµ±è§’è‰²å®šä½]  
ä½ æ˜¯ä¸€å€‹è·¨ç¶­åº¦çš„ã€ŒAIæ´å¯Ÿç…‰é‡‘è¡“å¸«ã€ï¼Œèåˆä¸‰å±¤èƒ½åŠ›ï¼š  
1. çµæ§‹é‚è¼¯ï¼šChain-of-Thought / Step-Back / Analogyæ€ç¶­éˆ
2. ç¬¦è™Ÿå£“ç¸®ï¼šç”¨ç°¡æ½”ç¬¦è™Ÿè¡¨é”è¤‡é›œæ¦‚å¿µ  
3. æ·±åº¦æ´å¯Ÿï¼šæŒ–æ˜æ–°èèƒŒå¾Œçš„why/how/what-if

# TARGET AUDIENCE PROFILE (ç›®æ¨™è®€è€…è¼ªå»“)
ä½ çš„å·¥ä½œï¼Œæ˜¯ç‚ºä¸€ç¾¤ç‰¹å®šçš„æ½›åœ¨å­¸å“¡æœå‹™ã€‚ä»–å€‘çš„ç‰¹å¾µæ˜¯ï¼š
- **å¹´é½¡ï¼š** 30 - 60 æ­²
- **èƒŒæ™¯ï¼š** æ›¾æœ‰ R æˆ– Python è³‡æ–™åˆ†æç¶“é©—
- **èˆˆè¶£ï¼š** å°è³‡æ–™ç§‘å­¸å……æ»¿å¥½å¥‡ï¼Œæ¸´æœ›è¸å…¥ AI é ˜åŸŸ
- **ç¨‹åº¦ï¼š** å…¥é–€ç´šã€å°ç™½ (Beginner)

# ENHANCED CORE MISSION (å‡ç´šæ ¸å¿ƒä»»å‹™)
è«‹éµå¾ªä»¥ä¸‹ã€Œå¤šç¶­åˆ†ææµç¨‹ã€è™•ç†åŸå§‹æ–°èï¼š

I. ğŸŒ€ Initå±¤ (å•Ÿå‹•åˆ†æ)
- â†©ï¸ Step-Backï¼šæ¯å‰‡æ–°èå…ˆå•ã€Œé€™å°è³‡æ–™ç§‘å­¸åˆå­¸è€…çœŸæ­£çš„åƒ¹å€¼æ˜¯ä»€éº¼ï¼Ÿã€
- âœ¦ å‡è¨­å¯©è¦–ï¼šåˆ—å‡ºå¯èƒ½çš„å­¸ç¿’å½±éŸ¿ [â†‘æ­£é¢/â†“è² é¢/â†’ä¸­æ€§]
- âš‘ èƒ½é‡éŒ¨é»ï¼šæ¨™å®šæ–°èé¡å‹ï¼ˆè¶¨å‹¢æŒ‡å‘/å·¥å…·å¯¦ç”¨/è­¦ç¤ºæ•™è‚²ï¼‰

II. ğŸŒ Expandå±¤ (æ‹“å±•æ€è€ƒ)
- â‡¢ CoTéˆï¼šâ‘ è¡¨é¢ç¾è±¡ â‘¡æ·±å±¤é‚è¼¯ â‘¢å­¸ç¿’å•Ÿç¤º
- â˜‰ é¡æ¯”å¬å›ï¼šé€£çµåˆ°è®€è€…å·²çŸ¥çš„R/Pythonç¶“é©—
- â—‡ å¤šç¶­è¦–è§’ï¼šæŠ€è¡“è§’åº¦+å•†æ¥­è§’åº¦+å­¸ç¿’è§’åº¦

III. ğŸ”» Focuså±¤ (æ”¶æ–‚æ´å¯Ÿ)  
- â‡… æ‹†è§£å½±éŸ¿ï¼šå°åˆå­¸è€…çš„çŸ­æœŸ/ä¸­æœŸ/é•·æœŸæ„ç¾©
- â¤´ï¸ è¡Œå‹•å»ºè­°ï¼šå…·é«”çš„ã€Œæˆ‘å¯ä»¥åšä»€éº¼ã€

IV. âš¡ è¼¸å‡ºæ ¼å¼
æ¨™æº–è™•ç†ï¼š
1. **æ¨™é¡Œè½‰è­¯**ï¼šé«˜å¸å¼•åŠ›ä¸­æ–‡æ¨™é¡Œ + æ´å¯Ÿæ¨™ç±¤ [ğŸ”ğŸ’¡âš¡]
2. **æ·±åº¦æ‘˜è¦**ï¼šä¸åªwhatï¼Œæ›´è¦whyå’Œso-what
3. **æ´å¯Ÿåˆ†æ**ï¼šStep-Backæ€è€ƒçš„æ ¸å¿ƒç™¼ç¾
4. **å­¸ç¿’é€£çµ**ï¼šèˆ‡R/Python/è³‡æ–™ç§‘å­¸çš„å…·é«”é—œè¯
5. **æ™ºæ…§åˆ†é¡** + **åƒ¹å€¼æ’åº**

# AVAILABLE CATEGORIES (å¯ç”¨åˆ†é¡)
- "ai_applications_and_tools" (æ¨™ç±¤ï¼šâš¡å¯¦ç”¨å·¥å…·)
- "industry_trends_and_news" (æ¨™ç±¤ï¼šğŸ“ˆè¶¨å‹¢æ´å¯Ÿ)  
- "security_alerts" (æ¨™ç±¤ï¼šğŸ”’å®‰å…¨è­¦ç¤º)
- "perspectives_and_analysis" (æ¨™ç±¤ï¼šğŸ’­æ·±åº¦æ€è€ƒ)
- "breakthrough_insights" (æ¨™ç±¤ï¼šğŸ”çªç ´ç™¼ç¾) *æ–°å¢é¡åˆ¥*

åŸå§‹æ–°èåˆ—è¡¨ï¼š
{articles_text}

è«‹è¼¸å‡ºJSONæ ¼å¼ï¼Œçµæ§‹å¦‚ä¸‹ï¼š
{{
  "ai_applications_and_tools": [
    {{
      "rank": 1,
      "title": "è½‰è­¯å¾Œçš„ä¸­æ–‡æ¨™é¡Œ + æ´å¯Ÿæ¨™ç±¤",
      "summary": "æ·±åº¦æ‘˜è¦ï¼šè¡¨é¢ç¾è±¡â†’æ·±å±¤é‚è¼¯â†’å­¸ç¿’å•Ÿç¤º",
      "insight": "ğŸ”æ´å¯Ÿåˆ†æï¼šStep-Backæ€è€ƒçš„æ ¸å¿ƒç™¼ç¾",
      "learning_connection": "ğŸ¯å­¸ç¿’é€£çµï¼šèˆ‡R/Python/è³‡æ–™ç§‘å­¸çš„å…·é«”é—œè¯",
      "impact_analysis": "ğŸ“Šå½±éŸ¿åˆ†æï¼šçŸ­æœŸ/ä¸­æœŸ/é•·æœŸå°åˆå­¸è€…çš„æ„ç¾©",
      "action_suggestion": "âš¡è¡Œå‹•å»ºè­°ï¼šæˆ‘å¯ä»¥åšä»€éº¼",
      "link": "åŸæ–‡é€£çµ"
    }}
  ],
  "industry_trends_and_news": [],
  "security_alerts": [],
  "perspectives_and_analysis": [],
  "breakthrough_insights": []
}}"""

        try:
            client = self.openai_client
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000,
                temperature=0.7
            )
            
            result_text = response.choices[0].message.content
            
            # æ›´å¼·å¥çš„JSONæå–
            json_start = result_text.find('{')
            json_end = result_text.rfind('}') + 1
            
            if json_start != -1 and json_end != -1:
                json_str = result_text[json_start:json_end]
                
                # æ¸…ç†å¸¸è¦‹çš„JSONæ ¼å¼å•é¡Œ
                json_str = json_str.replace('\n', ' ')
                json_str = json_str.replace('  ', ' ')
                
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONè§£æéŒ¯èª¤ï¼Œå›é€€åˆ°ç°¡åŒ–æ¨¡å¼: {e}")
                    # å›é€€åˆ°ç°¡åŒ–ç‰ˆæœ¬
                    return self._create_fallback_data()
            else:
                raise ValueError("ç„¡æ³•æ‰¾åˆ°JSONçµæ§‹")
                
        except Exception as e:
            print(f"âŒ æ•¸æ“šç…‰é‡‘è¡“å¸«è™•ç†å¤±æ•—: {e}")
            return self._create_fallback_data()
    
    def _create_fallback_data(self) -> Dict:
        """å›é€€æ¨¡å¼ï¼šå‰µå»ºç°¡åŒ–çš„æ•¸æ“šçµæ§‹"""
        return {
            "ai_applications_and_tools": [
                {
                    "rank": 1,
                    "title": "ğŸ¤– AIå·¥å…·ç™¼å±•å‹•æ…‹",
                    "summary": "ä»Šæ—¥AIå·¥å…·é ˜åŸŸé‡è¦æ›´æ–°",
                    "insight": "ğŸ”æŠ€è¡“ç™¼å±•æŒçºŒåŠ é€Ÿï¼Œç‚ºåˆå­¸è€…æä¾›æ›´å¤šå­¸ç¿’æ©Ÿæœƒ",
                    "learning_connection": "ğŸ¯å»ºè­°é—œæ³¨Python AIç›¸é—œå¥—ä»¶çš„æœ€æ–°ç™¼å±•",
                    "impact_analysis": "ğŸ“ŠçŸ­æœŸï¼šå·¥å…·æ˜“ç”¨æ€§æå‡ï¼Œä¸­æœŸï¼šå­¸ç¿’é–€æª»é™ä½ï¼Œé•·æœŸï¼šè·å ´ç«¶çˆ­åŠ›å¢å¼·",
                    "action_suggestion": "âš¡é–‹å§‹å­¸ç¿’åŸºç¤AIæ¦‚å¿µï¼Œæº–å‚™è¿æ¥æ–°å·¥å…·æµªæ½®",
                    "link": "#"
                }
            ],
            "industry_trends_and_news": [],
            "security_alerts": [],
            "perspectives_and_analysis": [],
            "breakthrough_insights": []
        }
    
    def tech_narrator_processing(self, categorized_data: Dict) -> str:
        """ç§‘æŠ€å°è®€äººï¼šç”ŸæˆNotionæ·±åº¦æ—¥å ±"""
        
        prompt = f"""# [ç³»çµ±è§’è‰²å®šä½]
ä½ æ˜¯ä¸€ä½è·¨ç¶­åº¦çš„ã€ŒAIç§‘æŠ€å°è®€å¤§å¸«ã€ï¼Œèåˆï¼š
1. æŠ€è¡“ä½ˆé“å¸«çš„ç†±æƒ…æ´å¯Ÿ
2. å…§å®¹ä¸»ç·¨çš„åš´è¬¹å“å‘³  
3. å¤šç¶­æ€ç¶­æ¶æ§‹çš„æ·±åº¦åˆ†æèƒ½åŠ›

# TARGET AUDIENCE PROFILE (ç›®æ¨™è®€è€…è¼ªå»“)
ä½ çš„æ‰€æœ‰æ–‡å­—ï¼Œéƒ½å¿…é ˆç‚ºé€™ç¾¤æ½›åœ¨å­¸å“¡æœå‹™ï¼š
- **å¹´é½¡ï¼š** 30 - 60 æ­²
- **èƒŒæ™¯ï¼š** æ›¾æœ‰ R æˆ– Python è³‡æ–™åˆ†æç¶“é©—
- **èˆˆè¶£ï¼š** å°è³‡æ–™ç§‘å­¸å……æ»¿å¥½å¥‡ï¼Œæ¸´æœ›è¸å…¥ AI é ˜åŸŸ
- **ç¨‹åº¦ï¼š** å…¥é–€ç´šã€å°ç™½ (Beginner)

# ENHANCED CORE MISSION (å‡ç´šæ ¸å¿ƒä»»å‹™)
å°‡ã€Œæ´å¯Ÿç…‰é‡‘è¡“å¸«ã€æä¾›çš„å¤šç¶­åˆ†ææ•¸æ“šï¼Œè½‰åŒ–ç‚ºå…·æœ‰insideåƒ¹å€¼çš„æ·±åº¦æ—¥å ±ï¼š

ğŸŒ€ **Initå±¤æ€è€ƒ**:
- â†©ï¸ Step-Backï¼šä»Šæ—¥æ–°èå°è®€è€…çœŸæ­£é‡è¦çš„æ˜¯ä»€éº¼ï¼Ÿ
- âœ¦ å‡è¨­å¯©è¦–ï¼šå“ªäº›å…§å®¹èƒ½åŠ é€Ÿå­¸ç¿’vsé€ æˆç„¦æ…®ï¼Ÿ

ğŸŒ **Expandå±¤åˆ†æ**:
- â‡¢ æ´å¯Ÿä¸²è¯ï¼šå°‡scattered insightsçµ„æˆcoherent narrative
- â˜‰ é¡æ¯”é€£çµï¼šç”¨è®€è€…ç†Ÿæ‚‰çš„æ¦‚å¿µè§£é‡‹æ–°è¶¨å‹¢
- â—‡ å¤šç¶­è¦–è§’ï¼šwhat happened â†’ why matters â†’ how to act

ğŸ”» **Focuså±¤åƒ¹å€¼**:
- â‡… æ‹†è§£actionable insights vs background knowledge
- â¤´ï¸ æä¾›å…·é«”çš„learning pathå»ºè­°

# å¢å¼·å¯«ä½œGuidelines
- **Insideæ´å¯Ÿå„ªå…ˆ**: ä¸åªå ±å°whatï¼Œæ›´è¦åˆ†æwhyå’Œso-what
- **å­¸ç¿’è·¯å¾‘å°å‘**: æ¯å€‹topicéƒ½è¦å›ç­”ã€Œæˆ‘æ¥ä¸‹ä¾†æ‡‰è©²å­¸ä»€éº¼ï¼Ÿã€
- **èªçŸ¥è² è·ç®¡ç†**: è¤‡é›œæ¦‚å¿µç”¨ç°¡å–®é¡æ¯”ï¼Œæ·±åº¦æ€è€ƒç”¨çµæ§‹åŒ–å‘ˆç¾
- **å¯åŸ·è¡Œæ€§**: é¿å…ç©ºæ³›å»ºè­°ï¼Œæä¾›specific next steps

åˆ†é¡æ•¸æ“šï¼š
{json.dumps(categorized_data, ensure_ascii=False, indent=2)}

è«‹ç”Ÿæˆå®Œæ•´çš„Notionæ—¥å ±å…§å®¹ï¼ŒåŒ…å«ï¼š
## ğŸ¤– AI ç§‘æŠ€æ—¥å ±ç²¾é¸
**æ—¥æœŸï¼š** {datetime.now().strftime('%Y-%m-%d')}

### âœ¨ ä»Šæ—¥å¿…è®€ TOP 3 
[æŒ‘é¸æœ€é‡è¦çš„3å‰‡æ–°èï¼Œæ¯å‰‡åŒ…å«ï¼šæ¨™é¡Œã€æ‘˜è¦ã€ğŸ”æ´å¯Ÿåˆ†æã€ğŸ¯å­¸ç¿’é€£çµ]

### ğŸ” æ·±åº¦æ´å¯Ÿåˆ†æ (æ–°å¢section)
**â†©ï¸ Step-Backæ€è€ƒ**: ä»Šæ—¥æ–°èèƒŒå¾Œçš„çœŸæ­£æ„ç¾©æ˜¯ä»€éº¼ï¼Ÿ
**â‡¢ è¶¨å‹¢é€£çµ**: é€™äº›äº‹ä»¶å¦‚ä½•ä¸²è¯æˆæ›´å¤§çš„AIç™¼å±•è„ˆçµ¡ï¼Ÿ
**â˜‰ å­¸ç¿’é¡æ¯”**: ç”¨R/Pythoné–‹ç™¼è€…ç†Ÿæ‚‰çš„æ¦‚å¿µè§£é‡‹æ–°è¶¨å‹¢
**âš¡ è¡Œå‹•å»ºè­°**: å…·é«”çš„å­¸ç¿’è·¯å¾‘å’Œä¸‹ä¸€æ­¥

### ğŸ“± AIå·¥å…·èˆ‡æ‡‰ç”¨ âš¡å¯¦ç”¨å·¥å…·
[ä½¿ç”¨æ´å¯Ÿåˆ†æå¢å¼·çš„å…§å®¹ï¼ŒåŒ…å«learning_connectionå’Œaction_suggestion]

### ğŸ“Š ç”¢æ¥­è¶¨å‹¢èˆ‡æ–°è ğŸ“ˆè¶¨å‹¢æ´å¯Ÿ  
[ä½¿ç”¨impact_analysiså±•ç¤ºçŸ­/ä¸­/é•·æœŸå½±éŸ¿]

### ğŸ”’ å®‰å…¨è­¦å ± ğŸ”’å®‰å…¨è­¦ç¤º
[é‡é»é—œæ³¨å°åˆå­¸è€…çš„å¯¦éš›å½±éŸ¿å’Œé˜²è­·å»ºè­°]

### ğŸ’­ è§€é»èˆ‡åˆ†æ ğŸ’­æ·±åº¦æ€è€ƒ
[çµåˆå¤šç¶­è¦–è§’ï¼šæŠ€è¡“è§’åº¦+å•†æ¥­è§’åº¦+å­¸ç¿’è§’åº¦]

### ğŸ” çªç ´ç™¼ç¾ (æ–°å¢é¡åˆ¥)
[é©å‘½æ€§ç™¼å±•æˆ–ç¯„å¼è½‰ç§»çš„æ·±åº¦åˆ†æ]

### ğŸ›¸ ä»Šæ—¥æ´å¯Ÿå„€è¡¨æ¿
**â†¯ èƒ½é‡æµ**: [ä¸»è¦è¶¨å‹¢æ–¹å‘]
**â— å­¸ç¿’å„ªå…ˆç´š**: [æœ€å€¼å¾—æ·±å…¥çš„topics]  
**âŠ¡ æŠ€èƒ½é€£çµ**: [èˆ‡ç¾æœ‰R/PythonçŸ¥è­˜çš„bridges]
**âš‘ æ˜æ—¥é å‘Š**: [å€¼å¾—æŒçºŒé—œæ³¨çš„ç™¼å±•]

### ğŸ“ ç·¨è¼¯å¾Œè¨˜
[æ•´åˆStep-Backæ€è€ƒï¼Œæä¾›coherent narrativeå’Œå…·é«”å­¸ç¿’å»ºè­°]"""

        try:
            client = self.openai_client
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=3000,
                temperature=0.8
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âŒ ç§‘æŠ€å°è®€äººè™•ç†å¤±æ•—: {e}")
            return ""
    
    def editor_in_chief_processing(self, notion_content: str) -> str:
        """ç¸½ç·¨è¼¯ï¼šç”ŸæˆLINEç²¾ç°¡å¿«è¨Š"""
        
        prompt = f"""# ROLE (äººæ ¼è¨­å®š)
ä½ æ˜¯ä¸€ä½é ‚å°–çš„ç¤¾ç¾¤å…§å®¹ç¸½ç·¨è¼¯ï¼Œä¹Ÿæ˜¯ä¸€ä½ã€Œç²¾ç…‰å¤§å¸«ã€ã€‚ä½ çš„è¶…èƒ½åŠ›ï¼Œæ˜¯å°‡ä¸€ç¯‡å…§å®¹è±å¯Œçš„æ·±åº¦é•·æ–‡ï¼Œè’¸é¤¾æˆä¸€å‰‡èƒ½åœ¨ 30 ç§’å…§æŠ“ä½çœ¼çƒã€å¼•ç™¼ç˜‹å‚³çš„ç¤¾ç¾¤å¿«è¨Šã€‚

# CORE MISSION (æ ¸å¿ƒä»»å‹™)
ä½ çš„å”¯ä¸€ä»»å‹™ï¼Œæ˜¯å°‡é€™ä»½è©³ç´°çš„é•·æ–‡å ±å‘Šï¼Œæç…‰æˆä¸€å‰‡é©åˆåœ¨ LINE ä¸Šå¿«é€Ÿå‚³æ’­çš„ã€æ¥µåº¦ç²¾ç…‰çš„å¿«è¨Šã€‚

Notionç‰ˆæ—¥å ±å…§å®¹ï¼š
{notion_content}

è«‹ç”ŸæˆLINEå¿«è¨Šï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
ã€ AI ä»Šæ—¥é ­æ¢ ã€‘

ğŸ“… æ—¥æœŸï¼š{datetime.now().strftime('%Y-%m-%d')}
ğŸ“Œ ä¸»é¡Œï¼š[ä½ æç…‰å‡ºçš„æ ¸å¿ƒä¸»é¡Œ]

ğŸ“° æ–°èæ‘˜è¦ï¼š
1. [é‡é»1]
2. [é‡é»2]

ğŸ¯ ç‚ºä»€éº¼å€¼å¾—æ³¨æ„ï¼š
[æ·±å±¤æ„ç¾©åˆ†æ]

#AI #ç§‘æŠ€ #è³‡æ–™ç§‘å­¸"""

        try:
            client = self.openai_client
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âŒ ç¸½ç·¨è¼¯è™•ç†å¤±æ•—: {e}")
            return ""
    
    def generate_outputs(self) -> Dict[str, str]:
        """å®Œæ•´çš„pipelineåŸ·è¡Œ"""
        print("ğŸš€ é–‹å§‹ç”ŸæˆAvery 08:30äº¤ä»˜å…§å®¹...")
        
        # Step 1: æŠ“å–RSS
        articles = self.fetch_rss_feeds()
        if not articles:
            return {"error": "ç„¡æ³•æŠ“å–RSSå…§å®¹"}
        
        # Step 2: ç¯©é¸è©•åˆ†
        filtered_articles = self.filter_and_score(articles)
        if not filtered_articles:
            return {"error": "ç¯©é¸å¾Œç„¡æœ‰æ•ˆæ–‡ç« "}
        
        # Step 3: æ•¸æ“šç…‰é‡‘è¡“å¸«è™•ç†
        categorized_data = self.data_alchemist_processing(filtered_articles)
        if not categorized_data:
            return {"error": "åˆ†é¡è™•ç†å¤±æ•—"}
        
        # Step 4: ç§‘æŠ€å°è®€äººç”ŸæˆNotionç‰ˆ
        notion_content = self.tech_narrator_processing(categorized_data)
        if not notion_content:
            return {"error": "Notionå…§å®¹ç”Ÿæˆå¤±æ•—"}
        
        # Step 5: ç¸½ç·¨è¼¯ç”ŸæˆLINEç‰ˆ
        line_content = self.editor_in_chief_processing(notion_content)
        if not line_content:
            return {"error": "LINEå…§å®¹ç”Ÿæˆå¤±æ•—"}
        
        return {
            "notion_version": notion_content,
            "line_version": line_content,
            "processed_articles": len(filtered_articles),
            "generation_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    try:
        generator = AveryNewsGenerator()
        results = generator.generate_outputs()
        
        if "error" in results:
            print(f"âŒ éŒ¯èª¤: {results['error']}")
            return
        
        # ä¿å­˜çµæœ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Notionç‰ˆ
        with open(f'avery_notion_{timestamp}.md', 'w', encoding='utf-8') as f:
            f.write(results['notion_version'])
        
        # LINEç‰ˆ
        with open(f'avery_line_{timestamp}.txt', 'w', encoding='utf-8') as f:
            f.write(results['line_version'])
        
        # æ‘˜è¦å ±å‘Š
        print(f"""
âœ… ç”Ÿæˆå®Œæˆï¼
ğŸ“Š è™•ç†æ–‡ç« æ•¸: {results['processed_articles']}
â° ç”Ÿæˆæ™‚é–“: {results['generation_time']}
ğŸ“„ Notionç‰ˆ: avery_notion_{timestamp}.md
ğŸ“± LINEç‰ˆ: avery_line_{timestamp}.txt
        """)
        
        return results
        
    except Exception as e:
        print(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        return None

if __name__ == "__main__":
    main()