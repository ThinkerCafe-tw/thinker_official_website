#!/usr/bin/env python3
"""
Thinker News æ¯æ—¥æ–°èè‡ªå‹•ç”Ÿæˆç³»çµ±
å¾ n8n é·ç§»åˆ° GitHub Actions

æ ¸å¿ƒæµç¨‹ï¼š
1. è®€å– RSS feeds
2. å°ç£æœ¬åœ°åŒ–ç¯©é¸
3. AI è™•ç†éˆï¼ˆGemini â†’ OpenAI â†’ OpenAIï¼‰
4. ç”Ÿæˆ HTML é é¢
5. æ›´æ–° GitHub repo
"""

import os
import sys
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv

# åŠ è¼‰ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('news_generation.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from rss_fetcher import fetch_all_rss_feeds
from news_filter import filter_and_score_news
from ai_processor import (
    setup_apis,
    process_with_data_alchemist,
    process_with_tech_narrator,
    process_with_editor_in_chief,
    process_with_html_generator
)
from html_generator import generate_daily_html, update_index_html
from utils import get_taiwan_date, validate_json_output
from execution_logger import ExecutionLogger


def main():
    """ä¸»åŸ·è¡Œæµç¨‹"""
    # åˆå§‹åŒ–åŸ·è¡Œæ—¥èªŒè¨˜éŒ„å™¨
    exec_logger = ExecutionLogger()

    try:
        # ============================================
        # æ­¥é©Ÿ 0: è¨­ç½® API Keys
        # ============================================
        logger.info("ğŸ”‘ è¨­ç½® API Keys...")
        openai_client = setup_apis()
        logger.info("âœ… API Keys è¨­ç½®å®Œæˆ")

        # ============================================
        # æ­¥é©Ÿ 1: ç”Ÿæˆä»Šæ—¥æ—¥æœŸï¼ˆå°ç£æ™‚å€ï¼‰
        # ============================================
        exec_logger.log_node_start("ç”Ÿæˆå°ç£æ™‚é–“æ—¥æœŸ", "date", "ç²å–å°ç£æ™‚å€çš„ç•¶å‰æ—¥æœŸ (UTC+8)")
        today_date = get_taiwan_date()
        logger.info(f"ğŸ“… ç”Ÿæˆä»Šæ—¥æ—¥æœŸ: {today_date}")
        exec_logger.log_node_success("ç”Ÿæˆå°ç£æ™‚é–“æ—¥æœŸ", today_date, {"æ—¥æœŸ": today_date})
        
        # ============================================
        # æ­¥é©Ÿ 2: è®€å–æ‰€æœ‰ RSS feeds
        # ============================================
        exec_logger.log_node_start("RSS Feed è®€å–", "rss", "ä¸¦è¡Œè®€å– 7 å€‹æ–°èä¾†æºçš„ RSS feeds")
        logger.info("ğŸ“¡ é–‹å§‹è®€å– RSS feeds...")
        all_feeds = fetch_all_rss_feeds(today_date)
        logger.info(f"âœ… æˆåŠŸè®€å– {len(all_feeds)} å‰‡æ–°è")

        # çµ±è¨ˆå„ä¾†æºçš„æ–°èæ•¸
        sources_count = {}
        for feed in all_feeds:
            source = feed.get('source', 'unknown')
            sources_count[source] = sources_count.get(source, 0) + 1

        exec_logger.log_node_success(
            "RSS Feed è®€å–",
            {"total_items": len(all_feeds), "sources_breakdown": sources_count},
            {"ç¸½æ–°èæ•¸": f"{len(all_feeds)} å‰‡", "ä¾†æºæ•¸": "7 å€‹", "æˆåŠŸç‡": "100%"}
        )
        
        # ============================================
        # æ­¥é©Ÿ 3: å°ç£æœ¬åœ°åŒ–ç¯©é¸èˆ‡è©•åˆ†
        # ============================================
        exec_logger.log_node_start("å°ç£æœ¬åœ°åŒ–ç¯©é¸", "filter", "ä½¿ç”¨æ™ºèƒ½è©•åˆ†ç³»çµ±ç¯©é¸å’Œæ’åºæ–°è")
        logger.info("ğŸ” åŸ·è¡Œå°ç£æœ¬åœ°åŒ–ç¯©é¸...")
        filtered_news = filter_and_score_news(all_feeds, today_date)
        logger.info(f"âœ… ç¯©é¸å¾Œä¿ç•™ {len(filtered_news)} å‰‡æ–°è")

        if len(filtered_news) == 0:
            logger.error("âŒ æ²’æœ‰æ–°èé€šéç¯©é¸ï¼Œæµç¨‹çµ‚æ­¢")
            exec_logger.log_node_error("å°ç£æœ¬åœ°åŒ–ç¯©é¸", Exception("æ²’æœ‰æ–°èé€šéç¯©é¸"))
            exec_logger.complete_execution("error")
            exec_logger.save_to_file("execution_log.json")
            sys.exit(1)

        # çµ±è¨ˆå°ç£ vs åœ‹éš›æ–°è
        local_count = sum(1 for n in filtered_news if n.get('is_taiwan_news', False))
        international_count = len(filtered_news) - local_count

        exec_logger.log_node_success(
            "å°ç£æœ¬åœ°åŒ–ç¯©é¸",
            {"filtered_items": len(filtered_news), "local_news": local_count, "international_news": international_count},
            {"ç¯©é¸å‰": f"{len(all_feeds)} å‰‡", "ç¯©é¸å¾Œ": f"{len(filtered_news)} å‰‡",
             "å°ç£æ–°è": f"{local_count} å‰‡", "åœ‹éš›æ–°è": f"{international_count} å‰‡"}
        )
        
        # ============================================
        # æ­¥é©Ÿ 4: AI è™•ç†éˆ
        # ============================================
        logger.info("ğŸ¤– é–‹å§‹ AI è™•ç†éˆ...")

        # 4.1 æ•¸æ“šç…‰é‡‘è¡“å¸« (Gemini)
        exec_logger.log_node_start("æ•¸æ“šç…‰é‡‘è¡“å¸« (Gemini)", "ai", "ä½¿ç”¨ Gemini AI é€²è¡Œæ¨™é¡Œè½‰è­¯ã€å…§å®¹æ‘˜è¦å’Œæ™ºèƒ½åˆ†é¡")
        logger.info("  âš—ï¸  æ•¸æ“šç…‰é‡‘è¡“å¸«è™•ç†ä¸­...")
        alchemist_output = process_with_data_alchemist(filtered_news, today_date)
        alchemist_json = validate_json_output(alchemist_output, "æ•¸æ“šç…‰é‡‘è¡“å¸«")

        # çµ±è¨ˆåˆ†é¡æ•¸é‡
        categories_count = {key: len(value) if isinstance(value, list) else 0
                           for key, value in alchemist_json.items() if isinstance(value, list)}

        exec_logger.log_node_success(
            "æ•¸æ“šç…‰é‡‘è¡“å¸« (Gemini)",
            alchemist_json,
            {"æ¨¡å‹": "Gemini 2.5 Flash", "è™•ç†æ–°è": f"{len(filtered_news)} å‰‡",
             "è¼¸å‡ºåˆ†é¡": f"{len(categories_count)} å€‹", "JSON ä¿®å¾©": "æ˜¯"}
        )

        # 4.2 ç§‘æŠ€å°è®€äºº (OpenAI)
        exec_logger.log_node_start("ç§‘æŠ€å°è®€äºº (OpenAI)", "ai", "ä½¿ç”¨ GPT-4o æ’°å¯«å®Œæ•´çš„ Notion æ—¥å ±")
        logger.info("  ğŸ“° ç§‘æŠ€å°è®€äººè™•ç†ä¸­...")
        narrator_output = process_with_tech_narrator(alchemist_json, today_date)
        narrator_json = validate_json_output(narrator_output, "ç§‘æŠ€å°è®€äºº")

        notion_text = narrator_json.get('notion_daily_report_text', '')
        notion_char_count = len(notion_text)

        exec_logger.log_node_success(
            "ç§‘æŠ€å°è®€äºº (OpenAI)",
            narrator_json,
            {"æ¨¡å‹": "GPT-4o", "å­—æ•¸": f"{notion_char_count:,} å­—", "æ®µè½æ•¸": "10+"}
        )

        # 4.3 ç¸½ç·¨è¼¯ (OpenAI)
        exec_logger.log_node_start("ç¸½ç·¨è¼¯ (OpenAI)", "ai", "ä½¿ç”¨ GPT-4o æç…‰ LINE ç²¾ç°¡å¿«è¨Š")
        logger.info("  âœï¸  ç¸½ç·¨è¼¯è™•ç†ä¸­...")
        editor_output = process_with_editor_in_chief(narrator_json, today_date)
        editor_json = validate_json_output(editor_output, "ç¸½ç·¨è¼¯")

        line_text = editor_json.get('line_message_text', '')
        line_char_count = len(line_text)

        exec_logger.log_node_success(
            "ç¸½ç·¨è¼¯ (OpenAI)",
            editor_json,
            {"æ¨¡å‹": "GPT-4o", "å­—æ•¸": f"{line_char_count} å­—"}
        )

        logger.info("âœ… AI è™•ç†éˆï¼ˆå‰3æ­¥ï¼‰å®Œæˆ")

        # 4.4 HTML ç”Ÿæˆå™¨ (Gemini)
        exec_logger.log_node_start("HTML ç”Ÿæˆå™¨ (Gemini)", "ai", "ä½¿ç”¨ Gemini ç”Ÿæˆå®Œæ•´ HTML æ–‡æª”ï¼ˆå°é½Š n8n æ¶æ§‹ï¼‰")
        logger.info("  ğŸ¨ HTML ç”Ÿæˆå™¨è™•ç†ä¸­...")

        html_full_content = process_with_html_generator(
            notion_content=narrator_json.get('notion_daily_report_text', ''),
            line_content=editor_json.get('line_message_text', ''),
            today_date=today_date
        )

        exec_logger.log_node_success(
            "HTML ç”Ÿæˆå™¨ (Gemini)",
            {"html_length": len(html_full_content)},
            {"æ¨¡å‹": "Gemini 2.0 Flash", "è¼¸å‡º": "å®Œæ•´ HTML æ–‡æª”"}
        )

        logger.info("âœ… AI è™•ç†éˆå®Œæˆ")

        # ============================================
        # æ­¥é©Ÿ 5: çµ„è£æœ€çµ‚è¼¸å‡º
        # ============================================
        logger.info("ğŸ“¦ çµ„è£æœ€çµ‚è¼¸å‡º...")
        
        notion_content = narrator_json.get('notion_daily_report_text', '')
        line_content = editor_json.get('line_message_text', '')
        website_url = f"https://thinkercafe-tw.github.io/thinker-news/{today_date}.html"
        
        final_output = {
            'final_date': today_date,
            'notion_content': notion_content,
            'line_content': line_content,
            'website_url': website_url,
            'news_json': {
                'date': today_date,
                'line_content': line_content,
                'notion_content': notion_content,
                'website_url': website_url,
                'generated_at': datetime.now().isoformat()
            }
        }
        
        # ============================================
        # æ­¥é©Ÿ 6: ç”Ÿæˆ HTML æ–‡ä»¶
        # ============================================
        exec_logger.log_node_start("HTML ç”Ÿæˆ", "html", "ç”Ÿæˆä»Šæ—¥æ–°èé é¢å’Œæ›´æ–°é¦–é ")
        logger.info("ğŸ“ ç”Ÿæˆ HTML æ–‡ä»¶...")

        # 6.1 ç”Ÿæˆä»Šæ—¥æ–°èé é¢
        daily_html_path = generate_daily_html(final_output, html_full_content)
        logger.info(f"âœ… ä»Šæ—¥æ–°èé é¢: {daily_html_path}")

        # 6.2 æ›´æ–°é¦–é  index.html
        index_html_path = update_index_html(today_date)
        logger.info(f"âœ… é¦–é æ›´æ–°: {index_html_path}")

        exec_logger.log_node_success(
            "HTML ç”Ÿæˆ",
            {"files": [f"{today_date}.html", "index.html", "latest.json"]},
            {"ç”Ÿæˆæ–‡ä»¶": "3 å€‹", "ä»Šæ—¥é é¢": f"{today_date}.html"}
        )

        # ============================================
        # æ­¥é©Ÿ 7: å„²å­˜ latest.json
        # ============================================
        logger.info("ğŸ’¾ å„²å­˜ latest.json...")
        latest_json_path = Path('latest.json')
        with open(latest_json_path, 'w', encoding='utf-8') as f:
            json.dump(final_output['news_json'], f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… latest.json å·²å„²å­˜")
        
        # ============================================
        # å®Œæˆ
        # ============================================
        logger.info("ğŸ‰ æ–°èç”Ÿæˆæµç¨‹å®Œæˆï¼")
        logger.info(f"ğŸ“Š çµ±è¨ˆè³‡è¨Š:")
        logger.info(f"  - åŸå§‹æ–°èæ•¸: {len(all_feeds)}")
        logger.info(f"  - ç¯©é¸å¾Œæ•¸é‡: {len(filtered_news)}")
        logger.info(f"  - ç”Ÿæˆæ—¥æœŸ: {today_date}")
        logger.info(f"  - ç¶²ç«™ URL: {website_url}")

        # å®ŒæˆåŸ·è¡Œæ—¥èªŒä¸¦ä¿å­˜
        exec_logger.complete_execution("success")
        exec_logger.save_to_file("execution_log.json")

        return 0

    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)

        # è¨˜éŒ„éŒ¯èª¤ä¸¦ä¿å­˜æ—¥èªŒ
        try:
            exec_logger.complete_execution("error")
            exec_logger.save_to_file("execution_log.json")
        except:
            pass  # å¦‚æœæ—¥èªŒä¿å­˜å¤±æ•—ï¼Œä¸è¦å½±éŸ¿éŒ¯èª¤è™•ç†

        return 1


if __name__ == "__main__":
    sys.exit(main())
